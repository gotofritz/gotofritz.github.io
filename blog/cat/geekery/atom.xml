<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Geekery | Fabrizio (Fritz) Stelluto]]></title>
  <link href="http://gotofritz.net/blog/cat/geekery/atom.xml" rel="self"/>
  <link href="http://gotofritz.net/"/>
  <updated>2015-05-29T01:32:37+02:00</updated>
  <id>http://gotofritz.net/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Why doesn't ls | echo work?]]></title>
    <link href="http://gotofritz.net/blog/geekery/why-pipe-echo-doesnt-work/"/>
    <updated>2015-05-28T22:58:00+02:00</updated>
    <id>http://gotofritz.net/blog/geekery/why-pipe-echo-doesnt-work</id>
    <content type="html"><![CDATA[<p><code>bash
$ ls | echo
$
</code>
Those new to bash often wonder why piping a command to <code>echo</code> doesn't do anything. Here's a quick explanation.</p>

<!--more-->


<h2>Streams vs. Arguments</h2>

<p>Bash commands are small (mostly..) independent programs which in theory <a href="https://en.wikipedia.org/wiki/Unix_philosophy#Do_One_Thing_and_Do_It_Well]">"do one  thing and do it well"</a>. To prove this, you can find out where they are in the filesystem with <code>which</code>
<code>bash
$ which ls
/usr/local/opt/coreutils/libexec/gnubin/ls
$
</code></p>

<p>Each of this programs has <i>streams</i> available to them - the default ones are STDIN to read from, STDOUT to write to, and STDERR to write errors to. Your terminal uses streams too - the keyboard is connected to STDIN, and when terminal gets some data or errors it will print them on the command line (unless you have redirected them).
``` bash</p>

<h1>the keyboard is STDIN to terminal - by default, what you type is both passed</h1>

<h1>to STDOUT, as well as kept around while it waits for you to hit return</h1>

<p>$ a b c</p>

<h1>when you type return, bash tries to run what you have typed as a command</h1>

<h1>in this case I had typed some gibberish - terminal print a message to STDERR</h1>

<h1>(for terminal, STDERR is the same as STDOUT, i.e. the command line)</h1>

<p>-bash: a: command not found</p>

<h1>now bash has recognized a program, cat</h1>

<p>$ cat</p>

<h1>STDIN (i.e. the keyboard) is still displayed by terminal as you type, but</h1>

<h1>when you hit return it will be processed by the command cat - until you type</h1>

<h1>CTRL-C to quit the command</h1>

<p>1
1</p>

<h1>All that cat does is simply copy STDIN to STDOUT every time you enter return.</h1>

<h1>that's why each line is repeated twice - the first line is what you type,</h1>

<h1>STDIN, handled by terminal; the second is what cat does, i.e. print to STDOUT</h1>

<p>2
2</p>

<h1>the > character redirects STDOUT to a file (&lt; does the same for STDIN)</h1>

<p>$ cat > output.txt</p>

<h1>here we still see what you type (STDIN) but the output of cat is going</h1>

<h1>directly into output.txt rather than STDOUT</h1>

<p>1
2
3
```</p>

<p>Streams are file-like handles which point directly to the kernel. What makes Unix so useful is that you can connect small programs together by joining the STDOUT of a program with the STDIN of another - using the pipe character, <code>|</code>, and because they are made to look like a file, it will just work. But you already knew that.
``` bash</p>

<h1>the STDOUT of the ps program is connected to the STDIN of grep</h1>

<p>$ ps -ef | grep httpd
....
$
```</p>

<p>Programs can also have <i>arguments</i> - these are values that are typically typed in and passed to the program by Bash as an array. A lot of programs support both arguments and STDIN / STDOUT; but they don't have to. So, grep for example loads its arguments to decide what to do:
<code>bash
$ grep "export" ~/.bash_profile
export PATH="$HOME/bin:$PATH"
$
</code>
In this case the first argument is a pattern to match, and the second a filename. <code>grep</code> finds occurrences of the pattern in the file.</p>

<p>But grep also supports STDIN:
<code>bash
$ grep "export"
I am now typing something
grep is looking for the string export - will it find it?
grep is looking for the string export - will it find it?
$
</code>
With only one argument, the programmer(s) who created <code>grep</code> decided to treat the first argument as a pattern as before, and to wait for input from STDIN since it wouldn't know which file to open. In the example above I start typing some random stuff and press return, and when grep finds the string matching the patter in my text it will spit out the string again.</p>

<h2>Why can't you pipe a command to echo?</h2>

<p>With all that out of the way, the explanation is quite simple - piping commands to <code>echo</code> does not work, because echo was not programmed to care about STDIN. All it's wired up to do is to take the <i>arguments</i> and copy them to STDOUT.
``` bash</p>

<h1>ls puts the output on STDOUT, which is connected to echo's STDIN</h1>

<h1>but echo ignores STDIN, all it cares about is command line arguments</h1>

<p>$ ls | echo
$</p>

<h1>takes arguments 1 2 3 and copies them to STDOUT</h1>

<p>$ echo 1 2 3
1 2 3
$
<code>
So if your command ignores STDIN, what you have to do is to find a different one which does the same thing, but also reads from STDIN. In the case of echo, that substitute is `cat`, which as we saw above, does what echo does, but using STDIN as input:
</code>
$ ls ~/ | cat
Applications
Desktop
...
$
```
But that's not the whole story.</p>

<h2>Using xargs to transform STDIN to arguments</h2>

<p>Turns out you <i>can</i> pipe to echo, if you use <code>xargs</code>. Xargs is a command that takes STDIN and turns it into arguments for a <i>command</i> (if it finds no command it will use echo). So:
``` bash</p>

<h1>xargs is basically creating the command: echo Applications Desktop Documents ...</h1>

<p>$ ls ~/ | xargs echo
Applications Desktop Documents ...
$
<code>``
Notice the difference between</code>cat<code>and</code>xargs`. cat adds newlines - it treats each space separated word as a different input. xargs instead removes newlines - part of its purpose is to normalize blank spaces, tabs and newlines into a consistent format.</p>

<p>You can see that better by passing the argument -1 to ls, which prints the arguments one per line:
<code>bash
$ ls -1 ~/
Applications
Desktop
...
$  ls -1 ~/ | xargs echo
Applications Desktop Documents ...
</code></p>

<h2>Further reading</h2>

<p>There is lots of info around the web, here are a couple of simple links:
<a href="http://www.westwind.com/reference/OS-X/commandline/pipes.html">Pipes and Redirects</a> and
<a href="http://www.december.com/unix/tutor/pipesfilters.html">Intro to Unix: Pipes and Filters</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to generate an error in a Gulp task]]></title>
    <link href="http://gotofritz.net/blog/geekery/how-to-generate-error-in-gulp-task/"/>
    <updated>2015-04-27T12:29:00+02:00</updated>
    <id>http://gotofritz.net/blog/geekery/how-to-generate-an-error-in-a-gulp-task</id>
    <content type="html"><![CDATA[<p>When writing a Gulp task that doesn't involve streams, how do you throw an error?</p>

<!--more-->


<h2>Motivation</h2>

<p><a href="http://gulpjs.com/">Gulp</a>, is a popular javscript build tool for web development. Gulp tasks are based around <a href="https://github.com/substack/stream-handbook">streams</a>; but sometimes streams are too clumsy when you want to do a simple task. Say you want to check a JSON file conforms to certain rule. It's much easier to require the file, check what you need to check, and then throw an error if you need to than it is opening the file as a stream and validating it.</p>

<p>But how do you throw an error in Gulp "the proper way", i.e. not just by throwing a standard JS error?</p>

<h2>Validating a package.json file</h2>

<p>I had to validate a package json file to make sure all packages were installed with the <code>--save-dev</code> flag. In other words, all dependencies should be in exact semantic format, <code>1.2.3</code> instead of the default <code>^1.2.3</code> or <code>~1.2.3</code>. It is simply enough in plain node, without the extra complication of streams - you require package.json, then test each dependency.</p>

<p>``` js
gulp.task(taskName, function (cb) {
  var gutil = require("gulp-util");
  var packageData = require("./package.json");</p>

<p>  // we test all three types of dependencies
  ["devDependencies", "dependencies", "optionalDependencies"]
  .forEach(function validateAnObj(key) {</p>

<pre><code>// load each dependency
Object.keys(packageData[key])
.forEach(function validateAField(field) {

  // check the version complies
  var hasInvalidVersion = (/[^0-9.]/.test(packageData[key][field]));

  // this is where the magic happens
  if (hasInvalidVersion) {
    throw new gutil.PluginError({
      plugin: taskName,
      message: field + " in " + key + " has non compliant versioning: " + packageData[key][field]
    });
  }
});
</code></pre>

<p>  });
});
```</p>

<h2>Throwing an error with gulp</h2>

<p>The easiset way to throw a gulp-y error is to use <code>gulp-util</code>, which has a PluginError that can be thrown. <a href="https://github.com/gulpjs/gulp-util#user-content-new-pluginerrorpluginname-message-options">Here is the documentation for PluginError</a>. <code>plugin</code> and <code>message</code> get outputted on separate lines; they are basically a title message and a message body.
There are also a couple of options that can be passed, do refer to the documentation.</p>

<h2>This is not using gulp the way it was meant to be</h2>

<p>There isn't always a benefit in turning simple problems into a stream problem. Hope this info was useful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[OS X DNS lookups too slow for local hosts]]></title>
    <link href="http://gotofritz.net/blog/geekery/os-x-dns-lookups-too-slow-for-local-hosts/"/>
    <updated>2015-04-24T13:03:00+02:00</updated>
    <id>http://gotofritz.net/blog/geekery/os-x-dns-lookups-too-slow-for-local-hosts</id>
    <content type="html"><![CDATA[<p>I have several local hosts set up on my dev OS X machine. The browser hangs for several seconds while trying to load them. Which doesn't make any sense, since they are local.</p>

<!--more-->


<p>The solution is to change the <code>/etc/hosts</code> file so that all hosts are on one line, the very first line where localhost is defined.</p>

<p>In other words, change from this...
<code>bash
127.0.0.1       localhost
255.255.255.255 broadcasthost
::1             localhost
fe80::1%lo0     localhost
127.0.0.1       my-host.dev
127.0.0.1       another-host.dev
127.0.0.1       oh-that-host.dev
</code></p>

<p>...to this.
<code>bash
127.0.0.1       localhost  my-host.dev another-host.dev oh-that-host.dev
255.255.255.255 broadcasthost
::1             localhost
fe80::1%lo0     localhost
</code></p>

<p>It <em>still</em> doesn't make sense, but it works and that's all that matters.</p>

<p><small>Answer from <a href="http://stackoverflow.com/questions/10064581/how-can-i-eliminate-slow-resolving-loading-of-localhost-virtualhost-a-2-3-secon">Stack Overflow</a></small></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Useful Alfred workflows for web development]]></title>
    <link href="http://gotofritz.net/blog/geekery/alfred-workflows-web-development/"/>
    <updated>2015-04-04T01:51:00+02:00</updated>
    <id>http://gotofritz.net/blog/geekery/useful-alfred-color-tool-for-os-x</id>
    <content type="html"><![CDATA[<p><a href="http://www.alfredapp.com/">Alfred App</a> has a couple of useful workflow for web developers.</p>

<!--more-->


<p>Alfred App is one of the things that make working on OS X a pleasure. There are lots of useful workflows out there, and using a folder inside Dropbox as the sync folder (Preferences &gt; Advanced &gt; Syncing.. ) allows me to share them among my work and home machines.</p>

<p>Here are a couple of workflows I find useful for web development.</p>

<h2><a href="http://www.packal.org/workflow/colors">Colors</a></h2>

<p>I can type a color directly into Alfred, say <code>#ff0000</code> or <code>rgb 1,45,87</code> and Alfred will show me a list of conversions in other formats, with a swatch in the color itself. Use <code>c name</code> for a CSS color name, say <code>c red</code>.</p>

<h2><a href="https://github.com/willfarrell/alfred-encode-decode-workflow">Encode/Decode</a></h2>

<p>Quickly convert from HTML or URL encoded text to plain by typing <code>decode &lt;TEXT&gt;</code>, or viceversa with  <code>encode &lt;TEXT&gt;</code>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Directory listings in Apache 2.4]]></title>
    <link href="http://gotofritz.net/blog/geekery/directory-listings-in-apache-2-4/"/>
    <updated>2015-03-07T23:14:00+01:00</updated>
    <id>http://gotofritz.net/blog/geekery/directory-listings-in-apache-2-dot-4</id>
    <content type="html"><![CDATA[<p>Yosemite updates Apache to 2.4. A couple of things stopped working from my previous installation, including autogenerated directory listings. Here's how I got them back.</p>

<!--more-->


<h2>Yosemite updates Apache from 2.2 to 2.4</h2>

<p>It copies the old httpd.conf to <code>/etc/apache2/httpd.conf~previous</code> and replaces it with a vannilla one. Annoying, but not too painful to replace, and it doesn't touch the vhosts. <a href="https://httpd.apache.org/docs/trunk/new_features_2_4.html">The list of 2.4 changes</a> doesn't include anything I actually use. Sadly that doesn't mean nothing important has changed - rather, they didn't bother to list things that matter to me.</p>

<h2>Apache "directory listing forbidden"</h2>

<p>I used to rely on the automatic directory listings generated by mod_autoidex, but they has stopped working. The logs give the message <code>No matching DirectoryIndex (index.html) found, and server-generated directory index forbidden by Options directive</code>. "Impossible!" I cry, the settings are right, and they always worked.</p>

<p>This is the DocumentRoot fragment of httpd.conf. <code>+Indexes</code> is the bit which is supposed to turn on auto-indexing. I use /Library/... for not so important documents I need to put under a webserver for whatever reason.
``` bash
DocumentRoot "/Library/WebServer/Documents"
<Directory "/Library/WebServer/Documents"></p>

<pre><code>Options +Indexes +FollowSymLinks
# etc
</code></pre>

<p></Directory>
```</p>

<p>And this is one of the virtual hosts. For serious dev work, I put my vhosts somewhere other than /Library/...
``` bash
<VirtualHost *:80></p>

<pre><code>DocumentRoot "/pth/to/somewhere/completely/different"
ServerName my-virtual-host.dev
ErrorLog "/private/var/log/apache2/my-virtual-host.dev-error_log"
CustomLog "/private/var/log/apache2/my-virtual-host.dev-access_log" common
</code></pre>

<p></VirtualHost>
```</p>

<p>What has changed is that now the options for DocumentRoot don't automatically carry over to folders which are not subdirectories of DocumentRoot. This can be easily fixed by changing virtual hosts to
``` bash
<VirtualHost *:80></p>

<pre><code>DocumentRoot "/pth/to/somewhere/completely/different"
ServerName my-virtual-host.dev
ErrorLog "/private/var/log/apache2/my-virtual-host.dev-error_log"
CustomLog "/private/var/log/apache2/my-virtual-host.dev-access_log" common
&lt;Directory "/pth/to/somewhere/completely/different"&gt;
    Options +Indexes
&lt;/Directory&gt;
</code></pre>

<p></VirtualHost>
```</p>

<p>That proves what the problem is, but it sucks having to do that for every virtual host. The solution is to add the directive for the common parent folder of all my virtual hosts in httpd.conf</p>

<p>``` bash
<Directory "/parent/of/somewhere/completely/different"></p>

<pre><code>Options +Indexes
</code></pre>

<p></Directory>
```</p>

<h2>Restart apache and all is well</h2>

<p>After a <code>sudo apachectl restart</code> everything works fine.</p>
]]></content>
  </entry>
  
</feed>
